{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Data Science\\\\NLP\\\\SentimentAnalysis\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Data Science\\\\NLP\\\\SentimentAnalysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPredictionConfig:\n",
    "    root_dir: Path\n",
    "    tokens_path: Path\n",
    "    final_model_path: Path\n",
    "    save_model_performance: str\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentimentAnalysis.constants import *\n",
    "from SentimentAnalysis.utils.common import read_yaml\n",
    "from SentimentAnalysis.utils.common import create_directories\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "            create_directories([self.config.dataStore_root])\n",
    "\n",
    "    #2. To be updated configuration inside config into Configuration\n",
    "\n",
    "    def get_model_prediction_config(self) -> ModelPredictionConfig:\n",
    "          config = self.config.model_prediction\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          model_prediction_config = ModelPredictionConfig(\n",
    "                root_dir=config.root_dir,\n",
    "                tokens_path=config.tokens_path, \n",
    "                final_model_path=config.final_model_path,\n",
    "                save_model_performance=config.save_model_performance\n",
    "                )\n",
    "\n",
    "          return model_prediction_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SentimentAnalysis.logging import logger\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentimentAnalysis.config.configuration import ConfigurationManager\n",
    "from SentimentAnalysis.components.eda_data_cleaning import DataCleaner\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from SentimentAnalysis.logging import logger\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self):\n",
    "        self.config = ConfigurationManager().get_model_prediction_config()\n",
    "        self.data_cleaner = DataCleaner(self.config)\n",
    "        self.max_review_length = 300\n",
    "        #self.tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "        #self.token = joblib.load(self.config.tokenizer_path)\n",
    "        self.model = joblib.load(self.config.final_model_path)\n",
    "\n",
    "    def predict(self):\n",
    "        token = joblib.load('dataStore/data_transformation/tokenizer.joblib')\n",
    "        #token = joblib.load(self.config.tokens_path)\n",
    "        text = input(\"Enter a review: \")\n",
    "        # Clean the user input using DataCleaner methods\n",
    "        text = self.data_cleaner.denoise_text(text)  # Call denoise_text on the instance\n",
    "        text = self.data_cleaner.remove_stopwords(text)  # Call remove_stopwords on the instance\n",
    "        text = self.data_cleaner.apply_stemming(text)  # Call apply_stemming on the instance\n",
    "        print(\"Cleaned input:\", text)\n",
    "\n",
    "        # token = joblib.load('dataStore/data_transformation/tokenizer.joblib')\n",
    "        \n",
    "        # Tokenize and pad the input\n",
    "        user_input_sequence = token.texts_to_sequences([text])\n",
    "        print(\"User input sequence:\", user_input_sequence)\n",
    "\n",
    "        user_input_padded = tf.keras.preprocessing.sequence.pad_sequences(user_input_sequence, self.max_review_length, padding='pre')\n",
    "        print(\"User input padded:\", user_input_padded)\n",
    "\n",
    "        # Make prediction\n",
    "        prediction_prob = self.model.predict(user_input_padded)[0][0]\n",
    "        \n",
    "        # Display the result\n",
    "        if prediction_prob > 0.5:\n",
    "            print(\"predicted_sentiment: Positive\")\n",
    "        else:\n",
    "            print(\"predicted_sentiment: Negative\")\n",
    "\n",
    "        print(\"Probability:\", prediction_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-12 15:58:28,888: INFO: common: YAML file loaded successfully: config\\config.yaml]\n",
      "[2023-08-12 15:58:28,890: INFO: common: YAML file loaded successfully: params.yaml]\n",
      "[2023-08-12 15:58:28,895: INFO: common: YAML file loaded successfully: schema.yaml]\n",
      "[2023-08-12 15:58:28,895: INFO: common: Created directory at: dataStore]\n",
      "[2023-08-12 15:58:28,899: INFO: common: Created directory at: dataStore/model_prediction]\n",
      "Cleaned input: im go disagre previous comment side maltin one second rate excess vicious western creak groan tri put across central theme wild west tame kick asid steadi march time would like tradit butch cassidi sundanc kid lack film poignanc charm andrew mclaglen direct limp final 30 minut real botch incomprehens strategi part hero charlton heston chris mitchum someon give holler explain set hillsid fire someth callous whole treatment rape scene woman reaction afterward certain ring true coburn plenti nasti half breed escap convict reveng fellow escape underdevelop theyr like bowl pin knock one one stori lurch forward michael park give one typic shifti letharg mumbl perform case appropri modern style sheriff symbol complac technolog progress bring\n",
      "User input sequence: [[70, 25, 2412, 658, 340, 403, 8308, 3, 224, 289, 2288, 3015, 607, 5534, 53, 139, 528, 1217, 476, 935, 1145, 2994, 937, 1111, 4713, 2584, 5, 14, 4, 1082, 6517, 6031, 5491, 143, 288, 2, 7926, 612, 1747, 5664, 94, 6206, 145, 1075, 110, 71, 4978, 3582, 6990, 64, 427, 6579, 3696, 1211, 4416, 215, 56, 536, 93, 702, 66, 9950, 146, 1895, 1010, 16, 180, 1331, 2331, 214, 1076, 228, 5396, 873, 1313, 306, 3616, 619, 2080, 1100, 1272, 6301, 429, 4, 3418, 3718, 1726, 3, 3, 13, 9891, 847, 458, 958, 56, 3, 622, 9121, 6090, 61, 335, 1618, 624, 364, 1721, 1358, 1783, 1407, 323]]\n",
      "User input padded: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   70   25 2412  658  340\n",
      "   403 8308    3  224  289 2288 3015  607 5534   53  139  528 1217  476\n",
      "   935 1145 2994  937 1111 4713 2584    5   14    4 1082 6517 6031 5491\n",
      "   143  288    2 7926  612 1747 5664   94 6206  145 1075  110   71 4978\n",
      "  3582 6990   64  427 6579 3696 1211 4416  215   56  536   93  702   66\n",
      "  9950  146 1895 1010   16  180 1331 2331  214 1076  228 5396  873 1313\n",
      "   306 3616  619 2080 1100 1272 6301  429    4 3418 3718 1726    3    3\n",
      "    13 9891  847  458  958   56    3  622 9121 6090   61  335 1618  624\n",
      "   364 1721 1358 1783 1407  323]]\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "predicted_sentiment: Positive\n",
      "Probability: 0.59136343\n"
     ]
    }
   ],
   "source": [
    "pipeline = PredictionPipeline()\n",
    "\n",
    "pipeline.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
